{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the data\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, mat_files, labels):\n",
    "        self.mat_files = mat_files\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mat_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        mat_file = self.mat_files[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load the .mat file\n",
    "        ecg_signal = scipy.io.loadmat(mat_file)['val'][0]  \n",
    "        return torch.tensor(ecg_signal, dtype=torch.float32), label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels\n",
    "labels_df = pd.read_csv('C:/Users/elkha/Desktop/EMA/EMA_173_2024-2025/DeepLearning/TP/RNN/Data/labels.csv', header=None, names=['filename', 'label'])\n",
    "labels_df['filename'] = labels_df['filename'].apply(lambda x: os.path.join('C:/Users/elkha/Desktop/EMA/EMA_173_2024-2025/DeepLearning/TP/RNN/Data/ECG_Data', x))\n",
    "label_encoder = LabelEncoder()\n",
    "labels_df['label'] = label_encoder.fit_transform(labels_df['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    labels_df['filename'].values,\n",
    "    labels_df['label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = ECGDataset(train_files, train_labels)\n",
    "test_dataset = ECGDataset(test_files, test_labels)\n",
    "\n",
    "# Create a custom collate function\n",
    "def collate_fn(batch):\n",
    "    signals = pad_sequence([item[0] for item in batch], batch_first=True)  # Pad sequences\n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)  # Gather labels\n",
    "    return signals, labels  # Return both signals and labels\n",
    "\n",
    "\n",
    "# Create DataLoader with the custom collate function\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super(RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = out[:, -1, :]  \n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for signals, labels in train_loader:  # This line should work now\n",
    "            signals = signals.unsqueeze(-1)  # Adding input_size dimension\n",
    "            outputs = model(signals)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for signals, labels in test_loader:\n",
    "            signals = signals.unsqueeze(-1)\n",
    "            outputs = model(signals)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.9140\n",
      "Epoch [2/10], Loss: 0.9163\n",
      "Epoch [3/10], Loss: 0.7499\n",
      "Epoch [4/10], Loss: 0.9919\n",
      "Epoch [5/10], Loss: 1.0057\n",
      "Epoch [6/10], Loss: 0.9886\n",
      "Epoch [7/10], Loss: 1.1056\n",
      "Epoch [8/10], Loss: 0.9597\n",
      "Epoch [9/10], Loss: 0.9915\n",
      "Epoch [10/10], Loss: 0.9966\n",
      "Accuracy: 60.97%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    input_size = 1  \n",
    "    hidden_size = 64\n",
    "    output_size = len(label_encoder.classes_)\n",
    "    num_layers = 1\n",
    "    num_epochs = 10\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    model = RNN(input_size, hidden_size, output_size, num_layers)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train the model\n",
    "    train_model(model, train_loader, criterion, optimizer, num_epochs)\n",
    "\n",
    "    # Test the model\n",
    "    test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2IA_ML_ADVANCED",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
